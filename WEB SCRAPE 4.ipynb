{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    " You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "# opening url\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]\n",
    "\n",
    "#scraping data from website\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\"):\n",
    "    Rank.append(i.text)\n",
    "Rank=Rank[0:30]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\"):\n",
    "    Name.append(i.text)\n",
    "Name=Name[0:30]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\"):\n",
    "    Artist.append(i.text)\n",
    "Artist=Artist[0:30]\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\"):\n",
    "    Upload_Date.append(i.text)\n",
    "Upload_Date=Upload_Date[0:30]\n",
    "\n",
    "Views=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\"):\n",
    "            Views.append(i.text)\n",
    "Views=Views[0:30]\n",
    "\n",
    "#creating dataframe from scraped data\n",
    "wiki=pd.DataFrame({})\n",
    "wiki['Rank']=Rank\n",
    "wiki['Name[1]']=Name\n",
    "wiki['Artist']=Artist\n",
    "wiki['Upload Date']=Upload_Date\n",
    "wiki['Views']=Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name[1]</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"[31]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Bath Song\"[33]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Dame Tu Cosita\"[39]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Wheels on the Bus\"[45]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lean On\"[47]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Hello\"[53]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Axel F\"[55]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                          Name[1]  \\\n",
       "0    1.                           \"Baby Shark Dance\"[22]   \n",
       "1    2.                                  \"Despacito\"[24]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[25]   \n",
       "3    4.                               \"Shape of You\"[26]   \n",
       "4    5.                              \"See You Again\"[27]   \n",
       "5    6.   \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "6    7.                                \"Uptown Funk\"[31]   \n",
       "7    8.  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "8    9.                                  \"Bath Song\"[33]   \n",
       "9   10.                              \"Gangnam Style\"[34]   \n",
       "10  11.                \"Phonics Song with Two Words\"[36]   \n",
       "11  12.                                      \"Sugar\"[37]   \n",
       "12  13.                                      \"Sorry\"[38]   \n",
       "13  14.                             \"Dame Tu Cosita\"[39]   \n",
       "14  15.                                       \"Roar\"[40]   \n",
       "15  16.                             \"Counting Stars\"[41]   \n",
       "16  17.                          \"Thinking Out Loud\"[42]   \n",
       "17  18.                                 \"Dark Horse\"[43]   \n",
       "18  19.                                      \"Faded\"[44]   \n",
       "19  20.                          \"Wheels on the Bus\"[45]   \n",
       "20  21.                               \"Shake It Off\"[46]   \n",
       "21  22.                                    \"Lean On\"[47]   \n",
       "22  23.                             \"Girls Like You\"[48]   \n",
       "23  24.                                   \"Bailando\"[49]   \n",
       "24  25.                                 \"Let Her Go\"[50]   \n",
       "25  26.                                   \"Mi Gente\"[51]   \n",
       "26  27.                                    \"Perfect\"[52]   \n",
       "27  28.                                      \"Hello\"[53]   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "29  30.                                     \"Axel F\"[55]   \n",
       "\n",
       "                            Artist        Upload Date Views  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016  8.74  \n",
       "1                       Luis Fonsi   January 12, 2017  7.39  \n",
       "2                      LooLoo Kids    October 8, 2016  5.43  \n",
       "3                       Ed Sheeran   January 30, 2017  5.34  \n",
       "4                      Wiz Khalifa      April 6, 2015  5.13  \n",
       "5                       Get Movies   January 31, 2012  4.44  \n",
       "6                      Mark Ronson  November 19, 2014  4.20  \n",
       "7                      Miroshka TV  February 27, 2018  4.14  \n",
       "8       Cocomelon – Nursery Rhymes        May 2, 2018  4.12  \n",
       "9                              Psy      July 15, 2012  4.08  \n",
       "10                       ChuChu TV      March 6, 2014  3.91  \n",
       "11                        Maroon 5   January 14, 2015  3.48  \n",
       "12                   Justin Bieber   October 22, 2015  3.44  \n",
       "13                       El Chombo      April 5, 2018  3.38  \n",
       "14                      Katy Perry  September 5, 2013  3.36  \n",
       "15                     OneRepublic       May 31, 2013  3.31  \n",
       "16                      Ed Sheeran    October 7, 2014  3.27  \n",
       "17                      Katy Perry  February 20, 2014  3.08  \n",
       "18                     Alan Walker   December 3, 2015  3.08  \n",
       "19      Cocomelon – Nursery Rhymes       May 24, 2018  3.07  \n",
       "20                    Taylor Swift    August 18, 2014  3.06  \n",
       "21                     Major Lazer     March 22, 2015  3.05  \n",
       "22                        Maroon 5       May 31, 2018  3.04  \n",
       "23                Enrique Iglesias     April 11, 2014  3.04  \n",
       "24                       Passenger      July 25, 2012  3.00  \n",
       "25                        J Balvin      June 29, 2017  2.93  \n",
       "26                      Ed Sheeran   November 9, 2017  2.86  \n",
       "27                           Adele   October 22, 2015  2.84  \n",
       "28                         Shakira       June 4, 2010  2.84  \n",
       "29                      Crazy Frog      June 16, 2009  2.83  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.head(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.to_csv('Question_1wiki.csv') # saving data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection with browser and opening url\n",
    "\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3) # 3 seconds delay\n",
    "# opening an element on webpage\n",
    "kk=driver.find_element_by_xpath(\"//a[@class='navigation__link navigation__link--in-drop-down']\")\n",
    "driver.get(kk.get_attribute(\"href\"))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating lists to append scraped data \n",
    "Match_title=[]\n",
    "\n",
    "Series=[] \n",
    "\n",
    "Place=[]\n",
    "\n",
    "Date=[]\n",
    "\n",
    "Time=[]\n",
    "day=[]\n",
    "month=[]\n",
    "\n",
    "#scraping data from website\n",
    "ss=driver.find_elements_by_xpath(\"//div[@class='fixture__format-strip']\")\n",
    "for i in ss:\n",
    "    Series.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "mt=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/strong\")\n",
    "for i in mt:\n",
    "    Match_title.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "plc=driver.find_elements_by_xpath(\"//div[@class='fixture__description u-unskewed-text']/p/span\")\n",
    "for i in plc:\n",
    "    Place.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "    \n",
    "dy=driver.find_elements_by_xpath(\"//span[@class='fixture__date']\")\n",
    "for i in dy:\n",
    "    day.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "mn=driver.find_elements_by_xpath(\"//span[@class='fixture__month']\")\n",
    "for i in mn:\n",
    "    month.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "tt=driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "for i in tt:\n",
    "    Time.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#creating data frame from scraped data\n",
    "temp=pd.DataFrame({})\n",
    "\n",
    "temp['day']=day\n",
    "temp['month']=month\n",
    "\n",
    "bcci=pd.DataFrame({})\n",
    "bcci['Match_title']=Match_title\n",
    "bcci['Series']=Series\n",
    "bcci['Place']=Place\n",
    "bcci['Time']=Time\n",
    "\n",
    "\n",
    "bcci['Date']=temp['day']+\" \"+ temp['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>TEST ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>15:00 IST</td>\n",
       "      <td>18 JUNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>14:30 IST</td>\n",
       "      <td>13 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>14:30 IST</td>\n",
       "      <td>16 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>ODI SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>14:30 IST</td>\n",
       "      <td>18 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>21 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>23 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>T20I SRI LANKA V INDIA 2021</td>\n",
       "      <td>R Premadasa Stadium, Colombo</td>\n",
       "      <td>19:00 IST</td>\n",
       "      <td>25 JULY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>04 AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>12 AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>25 AUGUST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>02 SEPTEMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>TEST ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>10 SEPTEMBER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_title                            Series  \\\n",
       "0        Final  TEST ICC WORLD TEST CHAMPIONSHIP   \n",
       "1      1st ODI        ODI SRI LANKA V INDIA 2021   \n",
       "2      2nd ODI        ODI SRI LANKA V INDIA 2021   \n",
       "3      3rd ODI        ODI SRI LANKA V INDIA 2021   \n",
       "4     1st T20I       T20I SRI LANKA V INDIA 2021   \n",
       "5     2nd T20I       T20I SRI LANKA V INDIA 2021   \n",
       "6     3rd T20I       T20I SRI LANKA V INDIA 2021   \n",
       "7     1st Test         TEST ENGLAND V INDIA 2021   \n",
       "8     2nd Test         TEST ENGLAND V INDIA 2021   \n",
       "9     3rd Test         TEST ENGLAND V INDIA 2021   \n",
       "10    4th Test         TEST ENGLAND V INDIA 2021   \n",
       "11    5th Test         TEST ENGLAND V INDIA 2021   \n",
       "\n",
       "                           Place       Time          Date  \n",
       "0    The Ageas Bowl, Southampton  15:00 IST       18 JUNE  \n",
       "1   R Premadasa Stadium, Colombo  14:30 IST       13 JULY  \n",
       "2   R Premadasa Stadium, Colombo  14:30 IST       16 JULY  \n",
       "3   R Premadasa Stadium, Colombo  14:30 IST       18 JULY  \n",
       "4   R Premadasa Stadium, Colombo  19:00 IST       21 JULY  \n",
       "5   R Premadasa Stadium, Colombo  19:00 IST       23 JULY  \n",
       "6   R Premadasa Stadium, Colombo  19:00 IST       25 JULY  \n",
       "7       Trent Bridge, Nottingham  15:30 IST     04 AUGUST  \n",
       "8                 Lord's, London  15:30 IST     12 AUGUST  \n",
       "9              Headingley, Leeds  15:30 IST     25 AUGUST  \n",
       "10              The Oval, London  15:30 IST  02 SEPTEMBER  \n",
       "11      Old Trafford, Manchester  15:30 IST  10 SEPTEMBER  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcci.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcci.to_csv('Question_2bcci.csv') # saving scraped data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting with web browser, opening url and opening elements on website\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url=('https://www.guru99.com/')\n",
    "driver.get(url)\n",
    "\n",
    "driver.find_element_by_xpath('//a[@title=\"Selenium\"]').click()\n",
    "\n",
    "driver.find_element_by_xpath('//a[@title=\"Selenium Exception Handling (Common Exceptions List)\"]').click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Name=[]\n",
    "Description=[]\n",
    "#scraping data from website\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\"):\n",
    "    Description.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exception name</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  \\\n",
       "0                 Exception name   \n",
       "1     ElementNotVisibleException   \n",
       "2  ElementNotSelectableException   \n",
       "3         NoSuchElementException   \n",
       "4           NoSuchFrameException   \n",
       "\n",
       "                                         Description  \n",
       "0                                        Description  \n",
       "1  This type of Selenium exception occurs when an...  \n",
       "2  This Selenium exception occurs when an element...  \n",
       "3  This Exception occurs if an element could not ...  \n",
       "4  This Exception occurs if the frame target to b...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from scraped data\n",
    "guru=pd.DataFrame({})\n",
    "guru['Name']=Name\n",
    "guru['Description']=Description\n",
    "guru.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "guru.to_csv('Question_3guru.csv') #saving file to csv from scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser and opening url\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url=('http://statisticstimes.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigating to desired page through clicking perticular elements on website\n",
    "economy=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "    \n",
    "gdp=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "try:\n",
    "    gdp.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(gd.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP18=[]\n",
    "GSDP19=[]\n",
    "Share17=[]\n",
    "GDPbillion=[]\n",
    "\n",
    "# scraping data from website\n",
    "rtags=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[1]\")\n",
    "for i in rtags:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "state_tags=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[2]\")\n",
    "for i in state_tags:\n",
    "    State.append(i.text)\n",
    "    \n",
    "gsdp18_tags=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[4]\")\n",
    "for i in gsdp18_tags:\n",
    "    GSDP18.append(i.text)\n",
    "    \n",
    "\n",
    "gsdp19_tags=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[3]\")\n",
    "for i in gsdp19_tags:\n",
    "    GSDP19.append(i.text)\n",
    "    \n",
    "share17_tags=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[5]\")\n",
    "for i in share17_tags:\n",
    "    Share17.append(i.text)\n",
    "    \n",
    "gdp=driver.find_elements_by_xpath(\"//div[@class='dataTables_wrapper']/table/tbody/tr/td[6]\")\n",
    "for i in gdp:\n",
    "    GDPbillion.append(i.text)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(17-18)</th>\n",
       "      <th>Share(2017)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19) GSDP(17-18) Share(2017)  \\\n",
       "0     1                Maharashtra   2,632,792           -      13.94%   \n",
       "1     2                 Tamil Nadu   1,630,208   1,845,853       8.63%   \n",
       "2     3              Uttar Pradesh   1,584,764   1,687,818       8.39%   \n",
       "3     4                    Gujarat   1,502,899           -       7.96%   \n",
       "4     5                  Karnataka   1,493,127   1,631,977       7.91%   \n",
       "5     6                West Bengal   1,089,898   1,253,832       5.77%   \n",
       "6     7                  Rajasthan     942,586   1,020,989       4.99%   \n",
       "7     8             Andhra Pradesh     862,957     972,782       4.57%   \n",
       "8     9                  Telangana     861,031     969,604       4.56%   \n",
       "9    10             Madhya Pradesh     809,592     906,672       4.29%   \n",
       "10   11                     Kerala     781,653           -       4.14%   \n",
       "11   12                      Delhi     774,870     856,112       4.10%   \n",
       "12   13                    Haryana     734,163     831,610       3.89%   \n",
       "13   14                      Bihar     530,363     611,804       2.81%   \n",
       "14   15                     Punjab     526,376     574,760       2.79%   \n",
       "15   16                     Odisha     487,805     521,275       2.58%   \n",
       "16   17                      Assam     315,881           -       1.67%   \n",
       "17   18               Chhattisgarh     304,063     329,180       1.61%   \n",
       "18   19                  Jharkhand     297,204     328,598       1.57%   \n",
       "19   20                Uttarakhand     245,895           -       1.30%   \n",
       "20   21            Jammu & Kashmir     155,956           -       0.83%   \n",
       "21   22           Himachal Pradesh     153,845     165,472       0.81%   \n",
       "22   23                        Goa      73,170      80,449       0.39%   \n",
       "23   24                    Tripura      49,845      55,984       0.26%   \n",
       "24   25                 Chandigarh      42,114           -       0.22%   \n",
       "25   26                 Puducherry      34,433      38,253       0.18%   \n",
       "26   27                  Meghalaya      33,481      36,572       0.18%   \n",
       "27   28                     Sikkim      28,723      32,496       0.15%   \n",
       "28   29                    Manipur      27,870      31,790       0.15%   \n",
       "29   30                   Nagaland      27,283           -       0.14%   \n",
       "30   31          Arunachal Pradesh      24,603           -       0.13%   \n",
       "31   32                    Mizoram      22,287      26,503       0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -           -   \n",
       "\n",
       "   GDP($ billion)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from scraped data\n",
    "GDP=pd.DataFrame({\"Rank\":Rank[0:33],\n",
    "                \"State\":State[0:33],\n",
    "                \"GSDP(18-19)\":GSDP18[0:33],\n",
    "                \"GSDP(17-18)\":GSDP19[0:33],\n",
    "                 \"Share(2017)\":Share17[0:33],\n",
    "                 \"GDP($ billion)\":GDPbillion[0:33]\n",
    "                })\n",
    "\n",
    "GDP.head(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP.to_csv('Question_4GDP.csv') # saving data frame to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url and navigating to desired page\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = 'https://github.com/'\n",
    "driver.get(url)\n",
    "Trending = driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3']/li[3]/a\")\n",
    "driver.get(Trending.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#creating lists to append scraped data\n",
    "Repository_title=[]\n",
    "Repository_description=[] \n",
    "Contributors_count=[] \n",
    "Language_used=[]\n",
    "\n",
    "# scraping data from website\n",
    "\n",
    "repository_title = driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]')\n",
    "for i in repository_title:\n",
    "    Repository_title.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "urls = []\n",
    "for i in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for URL in urls:\n",
    "    \n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        count = driver.find_element_by_xpath(\"//div[@class='BorderGrid-cell']/h2/a/span\").text\n",
    "        if count==' ':\n",
    "            Contributors_count.append('---')\n",
    "        else:\n",
    "            Contributors_count.append(count)\n",
    "    except NoSuchElementException :\n",
    "        Contributors_count.append(\"---\")\n",
    "        \n",
    "    try:    \n",
    "        description = driver.find_element_by_xpath('//p[@class=\"f4 mt-3\"]')\n",
    "        if description.text==\" \":\n",
    "            \n",
    "            Repository_description.append(\"---\")\n",
    "        else:\n",
    "            \n",
    "        \n",
    "            Repository_description.append(description.text)\n",
    "    \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Repository_description.append(\"---\")\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    try:\n",
    "        language_used = driver.find_element_by_xpath('//li[@class=\"d-inline\"]')\n",
    "        if language_used.text==\" \":\n",
    "            Language_used.append(\"---\")\n",
    "        else:\n",
    "            \n",
    "            Language_used.append(language_used.text.replace('\\n',' '))\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Language_used.append(\"---\")\n",
    "#creating dataframe from scraped data\n",
    "        \n",
    "GitHub_Repositories = pd.DataFrame({})\n",
    "GitHub_Repositories['Repository_Title'] = Repository_title[:23]\n",
    "GitHub_Repositories['Repository_Description'] = Repository_description[:23]\n",
    "GitHub_Repositories['Contributors_Count'] = Contributors_count[:23]\n",
    "GitHub_Repositories['Language_Used'] = Language_used[:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_Title</th>\n",
       "      <th>Repository_Description</th>\n",
       "      <th>Contributors_Count</th>\n",
       "      <th>Language_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebookresearch / AugLy</td>\n",
       "      <td>A data augmentations library for audio, image,...</td>\n",
       "      <td></td>\n",
       "      <td>Python 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programthink / zhao</td>\n",
       "      <td>【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵</td>\n",
       "      <td></td>\n",
       "      <td>Python 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>megaease / easegress</td>\n",
       "      <td>A Cloud Native traffic orchestration system</td>\n",
       "      <td>1</td>\n",
       "      <td>Go 98.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>keras-team / keras</td>\n",
       "      <td>Deep Learning for humans</td>\n",
       "      <td>50</td>\n",
       "      <td>Python 97.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibraheemdev / modern-unix</td>\n",
       "      <td>A collection of modern/faster/saner alternativ...</td>\n",
       "      <td></td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tailwindlabs / tailwindcss</td>\n",
       "      <td>A utility-first CSS framework for rapid UI dev...</td>\n",
       "      <td>156</td>\n",
       "      <td>JavaScript 79.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n8n-io / n8n</td>\n",
       "      <td>Free and open fair-code licensed node based Wo...</td>\n",
       "      <td></td>\n",
       "      <td>TypeScript 94.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>harvester / harvester</td>\n",
       "      <td>Open source hyperconverged infrastructure (HCI...</td>\n",
       "      <td>11</td>\n",
       "      <td>Go 97.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>organicmaps / organicmaps</td>\n",
       "      <td>🍃 Organic Maps is a better fork of MAPS.ME, an...</td>\n",
       "      <td>139</td>\n",
       "      <td>C++ 61.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>longhorn / longhorn</td>\n",
       "      <td>Cloud-Native distributed block storage built o...</td>\n",
       "      <td>59</td>\n",
       "      <td>Shell 69.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rancher / rancher</td>\n",
       "      <td>Complete container management platform</td>\n",
       "      <td>1,428</td>\n",
       "      <td>Go 81.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rustdesk / rustdesk</td>\n",
       "      <td>Yet another remote desktop software</td>\n",
       "      <td>6</td>\n",
       "      <td>Rust 95.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kwai / DouZero</td>\n",
       "      <td>[ICML 2021] DouZero: Mastering DouDizhu with S...</td>\n",
       "      <td></td>\n",
       "      <td>Python 98.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cariboulabs / cariboulite</td>\n",
       "      <td>CaribouLite turns any 40-pin Raspberry-Pi into...</td>\n",
       "      <td></td>\n",
       "      <td>C 72.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>willmcgugan / textual</td>\n",
       "      <td>A Text User Interface with Rich as the renderer</td>\n",
       "      <td></td>\n",
       "      <td>Python 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>prisma / prisma</td>\n",
       "      <td>Next-generation ORM for Node.js &amp; TypeScript |...</td>\n",
       "      <td>99</td>\n",
       "      <td>TypeScript 97.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>apache / incubator-shenyu</td>\n",
       "      <td>ShenYu is High-Performance Java API Gateway.</td>\n",
       "      <td>6</td>\n",
       "      <td>Java 99.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>academic / awesome-datascience</td>\n",
       "      <td>📝 An awesome Data Science repository to learn ...</td>\n",
       "      <td></td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vxunderground / MalwareSourceCode</td>\n",
       "      <td>Collection of malware source code for a variet...</td>\n",
       "      <td>4</td>\n",
       "      <td>Assembly 92.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bats3c / DarkLoadLibrary</td>\n",
       "      <td>LoadLibrary for offensive operations</td>\n",
       "      <td></td>\n",
       "      <td>C 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EssayKillerBrain / EssayKiller_V2</td>\n",
       "      <td>基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化</td>\n",
       "      <td></td>\n",
       "      <td>Python 63.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gohugoio / hugo</td>\n",
       "      <td>The world’s fastest framework for building web...</td>\n",
       "      <td>155</td>\n",
       "      <td>Go 99.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>thanos-io / thanos</td>\n",
       "      <td>Highly available Prometheus setup with long te...</td>\n",
       "      <td>65</td>\n",
       "      <td>Go 80.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Repository_Title  \\\n",
       "0            facebookresearch / AugLy   \n",
       "1                 programthink / zhao   \n",
       "2                megaease / easegress   \n",
       "3                  keras-team / keras   \n",
       "4           ibraheemdev / modern-unix   \n",
       "5          tailwindlabs / tailwindcss   \n",
       "6                        n8n-io / n8n   \n",
       "7               harvester / harvester   \n",
       "8           organicmaps / organicmaps   \n",
       "9                 longhorn / longhorn   \n",
       "10                  rancher / rancher   \n",
       "11                rustdesk / rustdesk   \n",
       "12                     kwai / DouZero   \n",
       "13          cariboulabs / cariboulite   \n",
       "14              willmcgugan / textual   \n",
       "15                    prisma / prisma   \n",
       "16          apache / incubator-shenyu   \n",
       "17     academic / awesome-datascience   \n",
       "18  vxunderground / MalwareSourceCode   \n",
       "19           bats3c / DarkLoadLibrary   \n",
       "20  EssayKillerBrain / EssayKiller_V2   \n",
       "21                    gohugoio / hugo   \n",
       "22                 thanos-io / thanos   \n",
       "\n",
       "                               Repository_Description Contributors_Count  \\\n",
       "0   A data augmentations library for audio, image,...                      \n",
       "1                        【编程随想】整理的《太子党关系网络》，专门揭露赵国的权贵                      \n",
       "2         A Cloud Native traffic orchestration system                  1   \n",
       "3                            Deep Learning for humans                 50   \n",
       "4   A collection of modern/faster/saner alternativ...                      \n",
       "5   A utility-first CSS framework for rapid UI dev...                156   \n",
       "6   Free and open fair-code licensed node based Wo...                      \n",
       "7   Open source hyperconverged infrastructure (HCI...                 11   \n",
       "8   🍃 Organic Maps is a better fork of MAPS.ME, an...                139   \n",
       "9   Cloud-Native distributed block storage built o...                 59   \n",
       "10             Complete container management platform              1,428   \n",
       "11                Yet another remote desktop software                  6   \n",
       "12  [ICML 2021] DouZero: Mastering DouDizhu with S...                      \n",
       "13  CaribouLite turns any 40-pin Raspberry-Pi into...                      \n",
       "14    A Text User Interface with Rich as the renderer                      \n",
       "15  Next-generation ORM for Node.js & TypeScript |...                 99   \n",
       "16       ShenYu is High-Performance Java API Gateway.                  6   \n",
       "17  📝 An awesome Data Science repository to learn ...                      \n",
       "18  Collection of malware source code for a variet...                  4   \n",
       "19               LoadLibrary for offensive operations                      \n",
       "20                     基于开源GPT2.0的初代创作型人工智能 | 可扩展、可进化                      \n",
       "21  The world’s fastest framework for building web...                155   \n",
       "22  Highly available Prometheus setup with long te...                 65   \n",
       "\n",
       "       Language_Used  \n",
       "0      Python 100.0%  \n",
       "1      Python 100.0%  \n",
       "2           Go 98.8%  \n",
       "3       Python 97.6%  \n",
       "4                ---  \n",
       "5   JavaScript 79.1%  \n",
       "6   TypeScript 94.9%  \n",
       "7           Go 97.1%  \n",
       "8          C++ 61.1%  \n",
       "9        Shell 69.6%  \n",
       "10          Go 81.2%  \n",
       "11        Rust 95.4%  \n",
       "12      Python 98.8%  \n",
       "13           C 72.9%  \n",
       "14     Python 100.0%  \n",
       "15  TypeScript 97.2%  \n",
       "16        Java 99.4%  \n",
       "17               ---  \n",
       "18    Assembly 92.1%  \n",
       "19          C 100.0%  \n",
       "20      Python 63.1%  \n",
       "21          Go 99.0%  \n",
       "22          Go 80.8%  "
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GitHub_Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "GitHub_Repositories.to_csv('Question_5GitHub_Repositories.csv')# saving data frame to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url\n",
    "charts=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a\")\n",
    "try:\n",
    "    charts.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(charts.get_attribute('href'))\n",
    "    \n",
    "time.sleep(3)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigating to desired page\n",
    "one=driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[1]/a/div[2]/div[1]\")\n",
    "try:\n",
    "    one.click()\n",
    "except ElementNotInteractableException:\n",
    "    \n",
    "    driver.get(one.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Name = []\n",
    "Artist = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "No_of_week = []\n",
    "# scraping data from website\n",
    "name = driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/span[2]/span[1]')\n",
    "artist = driver.find_elements_by_xpath('//ol[@class=\"chart-list__elements\"]/li/button/span[2]/span[2]')\n",
    "last_week = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "peak = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "no_of_week = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "\n",
    "for i in name:\n",
    "    \n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Name.append(\"---\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "for i in artist:\n",
    "    \n",
    "    try:\n",
    "        Artist.append(i.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Artist.append(\"---\")\n",
    "        \n",
    "\n",
    "\n",
    "for i in last_week:\n",
    "    \n",
    "    try:\n",
    "        Last_week_rank.append(i.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Last_week_rank.append(\"---\")\n",
    "        \n",
    "\n",
    "for i in peak:\n",
    "    \n",
    "    try:\n",
    "        Peak_rank.append(i.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        Peak_rank.append(\"---\")\n",
    "        \n",
    "\n",
    "\n",
    "for i in no_of_week:\n",
    "    \n",
    "    try:\n",
    "        No_of_week.append(i.text)\n",
    "        \n",
    "    except NoSuchElementException :\n",
    "        \n",
    "        No_of_week.append(\"---\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe from scraped data\n",
    "Billi_Board = pd.DataFrame({})\n",
    "Billi_Board['Song_Name'] = Name\n",
    "Billi_Board['Artist_Name'] = Artist\n",
    "Billi_Board['Last_Week_Rank'] = Last_week_rank\n",
    "Billi_Board['Peak_Rank'] = Peak_rank\n",
    "Billi_Board['Weeks_On_Board'] = No_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak_Rank</th>\n",
       "      <th>Weeks_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peaches</td>\n",
       "      <td>Justin Bieber Featuring Daniel Caesar &amp; Giveon</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Things A Man Oughta Know</td>\n",
       "      <td>Lainey Wilson</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Country Again</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Drunk (And I Don't Wanna Go Home)</td>\n",
       "      <td>Elle King &amp; Miranda Lambert</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If You Want To</td>\n",
       "      <td>Lil Baby &amp; Lil Durk</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Seeing Green</td>\n",
       "      <td>Nicki Minaj, Drake &amp; Lil Wayne</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song_Name  \\\n",
       "0                              Butter   \n",
       "1                            Good 4 U   \n",
       "2                          Levitating   \n",
       "3                             Peaches   \n",
       "4                 Leave The Door Open   \n",
       "..                                ...   \n",
       "95           Things A Man Oughta Know   \n",
       "96                      Country Again   \n",
       "97  Drunk (And I Don't Wanna Go Home)   \n",
       "98                     If You Want To   \n",
       "99                       Seeing Green   \n",
       "\n",
       "                                       Artist_Name Last_Week_Rank Peak_Rank  \\\n",
       "0                                              BTS              1         1   \n",
       "1                                   Olivia Rodrigo              2         1   \n",
       "2                        Dua Lipa Featuring DaBaby              3         2   \n",
       "3   Justin Bieber Featuring Daniel Caesar & Giveon              6         1   \n",
       "4         Silk Sonic (Bruno Mars & Anderson .Paak)              4         1   \n",
       "..                                             ...            ...       ...   \n",
       "95                                   Lainey Wilson             93        93   \n",
       "96                                    Thomas Rhett             89        73   \n",
       "97                     Elle King & Miranda Lambert             92        79   \n",
       "98                             Lil Baby & Lil Durk              -        99   \n",
       "99                  Nicki Minaj, Drake & Lil Wayne             67        12   \n",
       "\n",
       "   Weeks_On_Board  \n",
       "0               3  \n",
       "1               4  \n",
       "2              36  \n",
       "3              12  \n",
       "4              14  \n",
       "..            ...  \n",
       "95              4  \n",
       "96              6  \n",
       "97              7  \n",
       "98              1  \n",
       "99              4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billi_Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Billi_Board.to_csv('Question_6Billi_Board.csv')# saving data frame to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to desired page\n",
    "rec=driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a\")\n",
    "urlss=rec.get_attribute(\"href\")\n",
    "driver.get(urlss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your value: Data Science\n"
     ]
    }
   ],
   "source": [
    "# accepting values as input and searching data based on it\n",
    "search_bar = driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\")    # Locating searc_bar by id\n",
    "search_bar.clear()    # clearing search_bar\n",
    "val = input(\"Enter your value: \")\n",
    "search_bar.send_keys(val)      \n",
    "\n",
    "btn=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skill_Hire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>, Mean Stack , javascript , angularjs , mongod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop , Spark , Digital Strategy , Data Archi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "      <td>Analytics , Business Intelligence , Business A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Analytics &amp; Business Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Trivandrum</td>\n",
       "      <td>Machine Learning , algorithms , Go Getter , Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Qa , Ui , ux , Java Developer , Java Architect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>MoneyTap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>IT Skills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Bhopal</td>\n",
       "      <td>Big Data , Hadoop , Data Analytics , Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "      <td>Mid Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>IT-Software/Software Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Data Analytics , Data Science , Machine Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Pune</td>\n",
       "      <td>High Level, Mid Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager - Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Java , Net , Angularjs , Hr , Infrastructure ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private Limited</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>High Level, Top Mangement Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science , Hadoop , Rpas , Devops , Python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Others</td>\n",
       "      <td>Signal Processing , Machine Learning , Neural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>R.S Consultancy &amp; Services</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Web Technologies , Project Management , Softwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Independent Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>S. Finance Manager , Freshers , Experience , S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "      <td>Data Analytics , Managed Services , Team Leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>ASCO consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. India</td>\n",
       "      <td>Aligarh</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Python , Php , Qa Automation , Ui , Wordpre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head-Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Suntech Global (Since Feb-2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Indore</td>\n",
       "      <td>Top Mangement Level, Junior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>Data Science , Node.js , Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director, Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>MYSORE</td>\n",
       "      <td>MRP Advisers (Since Oct-2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td></td>\n",
       "      <td>Granular.ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sunny Sharma</td>\n",
       "      <td>Managing Director - HR</td>\n",
       "      <td>Western Service Providers</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Software Professionals , Engineering , Technic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                    Ruchi Dhote   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                   Kapil Devang   \n",
       "16                                  Manisha Yadav   \n",
       "17                                    Riya Rajesh   \n",
       "18                           Rashmi Bhattacharjee   \n",
       "19                                  Faizan Kareem   \n",
       "20                                 Rithika dadwal   \n",
       "21                                  Azahar Shaikh   \n",
       "22                             Sandhya Khandagale   \n",
       "23                                      Shaun Rao   \n",
       "24                                          Manas   \n",
       "25                                          kumar   \n",
       "26                                   Sunil Vedula   \n",
       "27                                    Rajat Kumar   \n",
       "28                                    Priya Khare   \n",
       "29                                Dhruv Dev Dubey   \n",
       "30                                      Jayanth N   \n",
       "31                                       SREEDHAR   \n",
       "32                              Radha Manivasagam   \n",
       "33                                  Prateek Kumar   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "48                                 Shailja Mishra   \n",
       "49                                   Sunny Sharma   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                         Founder & CEO   \n",
       "5         Recruitment - Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14                         HR Team Lead   \n",
       "15                           HR Manager   \n",
       "16                         HR Executive   \n",
       "17           Manager Talent Acquisition   \n",
       "18                              HR Head   \n",
       "19                           HR MANAGER   \n",
       "20                         HR Recruiter   \n",
       "21                    Company Recruiter   \n",
       "22                         HR Recruiter   \n",
       "23            Manager - Human Resources   \n",
       "24              Lead Talent acquisition   \n",
       "25                           Proprietor   \n",
       "26                                  CEO   \n",
       "27                        Founder & CEO   \n",
       "28                       Senior Manager   \n",
       "29             Company Recruitment Head   \n",
       "30                      Project Manager   \n",
       "31               Recruitment Consultant   \n",
       "32                         HR Executive   \n",
       "33                                 Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head-Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43            Director, Global Delivery   \n",
       "44                           Co-Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48                           HR Manager   \n",
       "49               Managing Director - HR   \n",
       "\n",
       "                                              Company  \\\n",
       "0                                Data Science Network   \n",
       "1                       Shore Infotech India Pvt. Ltd   \n",
       "2                            MARSIAN Technologies LLP   \n",
       "3               Enerlytics Software Solutions Pvt Ltd   \n",
       "4                                     LibraryXProject   \n",
       "5          Apidel Technologies Division of Transpower   \n",
       "6                                                IFMR   \n",
       "7                         Techvantage Systems Pvt Ltd   \n",
       "8                          Weupskill- Live Wire India   \n",
       "9                    CBL Data Science Private Limited   \n",
       "10                                 Innominds Software   \n",
       "11                                           MoneyTap   \n",
       "12                 QuantMagnum Technologies Pvt. Ltd.   \n",
       "13                              Bristlecone India Ltd   \n",
       "14                                  SocialPrachar.com   \n",
       "15                                     BISP Solutions   \n",
       "16                                           Easi Tax   \n",
       "17                        Novelworx Digital Solutions   \n",
       "18       AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED   \n",
       "19                      FirstTech Consaltants Pvt.Ltd   \n",
       "20                                   Affine Analytics   \n",
       "21                    NEAL ANALYTICS SERVICES PVT LTD   \n",
       "22                    Compumatrice Multimedia Pvt Ltd   \n",
       "23                                 Exela Technologies   \n",
       "24    Autumn Leaf Consulting Services Private Limited   \n",
       "25                                            trainin   \n",
       "26                               Nanoprecise Sci Corp   \n",
       "27                         R.S Consultancy & Services   \n",
       "28                             Independent Consultant   \n",
       "29                                       Confidential   \n",
       "30           Dollarbird Information Services Pvt, Ltd   \n",
       "31        JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "32                                         Techcovery   \n",
       "33                                            Trisect   \n",
       "34                                    ASCO consulting   \n",
       "35                                            NY INST   \n",
       "36  3D India Staffing Research & Consulting Co. India   \n",
       "37                                        O.C. Tanner   \n",
       "38                                      Demand Matrix   \n",
       "39                                MADHUSUDHAN SRIDHAR   \n",
       "40                                     Suntech Global   \n",
       "41                           Strategic Consulting Lab   \n",
       "42                               Impel Labs Pvt. Ltd.   \n",
       "43                                       MRP Advisers   \n",
       "44                      Saras Solutions India Pvt Ltd   \n",
       "45                                        WildJasmine   \n",
       "46                                LNT Private Limited   \n",
       "47                                        Granular.ai   \n",
       "48                                  Certybox Pvt.Ltd.   \n",
       "49                          Western Service Providers   \n",
       "\n",
       "                    Location  \\\n",
       "0                      Delhi   \n",
       "1   Hyderabad / Secunderabad   \n",
       "2                       Pune   \n",
       "3                  Ahmedabad   \n",
       "4              UK - (london)   \n",
       "5          Vadodara / Baroda   \n",
       "6                    Chennai   \n",
       "7                 Trivandrum   \n",
       "8                     Indore   \n",
       "9      Bengaluru / Bangalore   \n",
       "10  Hyderabad / Secunderabad   \n",
       "11     Bengaluru / Bangalore   \n",
       "12                    Mumbai   \n",
       "13                      Pune   \n",
       "14  Hyderabad / Secunderabad   \n",
       "15                    Bhopal   \n",
       "16               Navi Mumbai   \n",
       "17                    Cochin   \n",
       "18                     Delhi   \n",
       "19  Hyderabad / Secunderabad   \n",
       "20                      Pune   \n",
       "21                      Pune   \n",
       "22                      Pune   \n",
       "23                      Pune   \n",
       "24     Bengaluru / Bangalore   \n",
       "25     Bengaluru / Bangalore   \n",
       "26                    Others   \n",
       "27                     Delhi   \n",
       "28     Bengaluru / Bangalore   \n",
       "29     Bengaluru / Bangalore   \n",
       "30           Mysoru / Mysore   \n",
       "31  Hyderabad / Secunderabad   \n",
       "32     Bengaluru / Bangalore   \n",
       "33                     Noida   \n",
       "34                 New Delhi   \n",
       "35                   Chennai   \n",
       "36                   Aligarh   \n",
       "37            Salt Lake City   \n",
       "38                      Pune   \n",
       "39     Bengaluru / Bangalore   \n",
       "40                    Mumbai   \n",
       "41                    Indore   \n",
       "42     Bengaluru / Bangalore   \n",
       "43                    MYSORE   \n",
       "44  Hyderabad / Secunderabad   \n",
       "45     Bengaluru / Bangalore   \n",
       "46                    Mumbai   \n",
       "47                             \n",
       "48                     Noida   \n",
       "49                    Mumbai   \n",
       "\n",
       "                                           Skill_Hire  \n",
       "0   Classic ASP Developer , Internet Marketing Pro...  \n",
       "1   .Net , Java , Data Science , Linux Administrat...  \n",
       "2                             Mid Level, Junior Level  \n",
       "3   , Mean Stack , javascript , angularjs , mongod...  \n",
       "4   Hadoop , Spark , Digital Strategy , Data Archi...  \n",
       "5   Analytics , Business Intelligence , Business A...  \n",
       "6                   Analytics & Business Intelligence  \n",
       "7   Machine Learning , algorithms , Go Getter , Co...  \n",
       "8                          Weupskill- Live Wire India  \n",
       "9                             Junior Level, Mid Level  \n",
       "10  Qa , Ui , ux , Java Developer , Java Architect...  \n",
       "11                                           MoneyTap  \n",
       "12                 QuantMagnum Technologies Pvt. Ltd.  \n",
       "13                                          IT Skills  \n",
       "14                            Junior Level, Mid Level  \n",
       "15  Big Data , Hadoop , Data Analytics , Data Science  \n",
       "16                                          Mid Level  \n",
       "17                      IT-Software/Software Services  \n",
       "18                     Mid Level, Top Mangement Level  \n",
       "19  Data Analytics , Data Science , Machine Learni...  \n",
       "20                            Junior Level, Mid Level  \n",
       "21                              Mid Level, High Level  \n",
       "22                              High Level, Mid Level  \n",
       "23  Java , Net , Angularjs , Hr , Infrastructure ,...  \n",
       "24                    High Level, Top Mangement Level  \n",
       "25  Data Science , Hadoop , Rpas , Devops , Python...  \n",
       "26  Signal Processing , Machine Learning , Neural ...  \n",
       "27  Web Technologies , Project Management , Softwa...  \n",
       "28                             Independent Consultant  \n",
       "29  S. Finance Manager , Freshers , Experience , S...  \n",
       "30   Data Analytics , Managed Services , Team Leading  \n",
       "31        JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED  \n",
       "32                                       Junior Level  \n",
       "33                                       Junior Level  \n",
       "34                                    ASCO consulting  \n",
       "35                            Mid Level, Junior Level  \n",
       "36  3D India Staffing Research & Consulting Co. India  \n",
       "37                           Junior Level, High Level  \n",
       "38        Python , Php , Qa Automation , Ui , Wordpre  \n",
       "39                                MADHUSUDHAN SRIDHAR  \n",
       "40                    Suntech Global (Since Feb-2018)  \n",
       "41                  Top Mangement Level, Junior Level  \n",
       "42                 Data Science , Node.js , Angularjs  \n",
       "43                      MRP Advisers (Since Oct-2017)  \n",
       "44                      Saras Solutions India Pvt Ltd  \n",
       "45  java , hadoop , r , Machine Learning , spark ,...  \n",
       "46                              Mid Level, High Level  \n",
       "47                                        Granular.ai  \n",
       "48                                  Certybox Pvt.Ltd.  \n",
       "49  Software Professionals , Engineering , Technic...  "
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#creating lists to append scraped data\n",
    "\n",
    "Name = []\n",
    "Position = []\n",
    "Company = []\n",
    "Location = []\n",
    "Skill = []\n",
    "\n",
    "# scraping data from website\n",
    "\n",
    "names = driver.find_elements_by_xpath('//div[@class=\"recInfo\"]/div[1]/p/a[1]')\n",
    "urls = []\n",
    "for i in names:\n",
    "    Name.append(i.text)\n",
    "    urls.append(i.get_attribute('href'))\n",
    "    \n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    Position.append(driver.find_element_by_xpath('//div[@class=\"rFrame fl infoWrapper\"]/div[3]').text)\n",
    "    Company.append(driver.find_element_by_xpath('//div[@class=\"rFrame fl infoWrapper\"]/div[4]').text)\n",
    "    try:\n",
    "        Location.append(driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[1]/div[2]/div[5]/a').text)\n",
    "    except:\n",
    "        Location.append('-')\n",
    "    Skill.append(driver.find_element_by_xpath('//div[@class=\"fadeOutParent readMoreHt100 \"]/div[2]/div/p').text)\n",
    "    \n",
    "    \n",
    "#creating dataframe from scraped data\n",
    "\n",
    "    \n",
    "DS_Recruiters = pd.DataFrame({})\n",
    "DS_Recruiters['Name'] = Name\n",
    "DS_Recruiters['Designation'] = Position\n",
    "DS_Recruiters['Company'] = Company\n",
    "DS_Recruiters['Location'] = Location\n",
    "DS_Recruiters['Skill_Hire'] = Skill\n",
    "\n",
    "DS_Recruiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DS_Recruiters.to_csv('Question_7S_Recruiters.csv')# saving data frame to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scraping data from website\n",
    "\n",
    "\n",
    "bn=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "for i in bn:\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "    \n",
    "an=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "for i in an:\n",
    "    Author_name.append(i.text)\n",
    "    \n",
    "vs=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "for i in vs:\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "ps=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "for i in ps:\n",
    "    Publisher.append(i.text)\n",
    "\n",
    "gen=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "for i in gen:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Book_name    Author_name Volumes_sold  \\\n",
       "0                          Da Vinci Code,The     Brown, Dan    5,094,805   \n",
       "1       Harry Potter and the Deathly Hallows  Rowling, J.K.    4,475,152   \n",
       "2   Harry Potter and the Philosopher's Stone  Rowling, J.K.    4,200,654   \n",
       "3  Harry Potter and the Order of the Phoenix  Rowling, J.K.    4,179,479   \n",
       "4                       Fifty Shades of Grey   James, E. L.    3,758,936   \n",
       "\n",
       "      Publisher                        Genre  \n",
       "0    Transworld  Crime, Thriller & Adventure  \n",
       "1    Bloomsbury           Children's Fiction  \n",
       "2    Bloomsbury           Children's Fiction  \n",
       "3    Bloomsbury           Children's Fiction  \n",
       "4  Random House              Romance & Sagas  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#creating dataframe from scraped data\n",
    "\n",
    "guard=pd.DataFrame({})\n",
    "guard['Book_name']=Book_name\n",
    "guard['Author_name']=Author_name\n",
    "guard['Volumes_sold']=Volumes_sold\n",
    "guard['Publisher']=Publisher\n",
    "guard['Genre']=Genre\n",
    "\n",
    "guard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard.to_csv('Question_8guard.csv')# saving data frame to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Name=[]\n",
    "\n",
    "Year_span=[] \n",
    "\n",
    "Genre=[]\n",
    "\n",
    "Run_time=[]\n",
    "\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "# scraping data from website\n",
    "\n",
    "nn=driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\")\n",
    "for i in nn:\n",
    "    Name.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "ys=driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in ys:\n",
    "    Year_span.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "gen=driver.find_elements_by_xpath(\"//span[@class='genre']\")\n",
    "for i in gen:\n",
    "    Genre.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "    \n",
    "rt=driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rt:\n",
    "    Ratings.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "rtim=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "for i in rtim:\n",
    "    Run_time.append(i.text.replace('\\n',' '))\n",
    "        \n",
    "    \n",
    "vt=driver.find_elements_by_xpath(\"//span[@name='nv']\")\n",
    "for i in vt:\n",
    "    Votes.append(i.text.replace('\\n',' '))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,823,093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>863,747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.3  1,823,093  \n",
       "1    51 min     8.7    863,747  \n",
       "2    44 min     8.2    874,455  \n",
       "3    60 min     7.6    262,676  \n",
       "4    43 min     7.6    224,017  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,576  \n",
       "96   50 min     7.8     55,064  \n",
       "97   42 min       8    167,711  \n",
       "98   45 min     7.1     34,882  \n",
       "99  572 min     8.6    191,402  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from scraped data\n",
    "\n",
    "imdb1=pd.DataFrame({})\n",
    "\n",
    "imdb1['Name']=Name\n",
    "imdb1['Year_span']=Year_span\n",
    "imdb1['Genre']=Genre\n",
    "imdb1['Run_time']=Run_time\n",
    "imdb1['Ratings']=Ratings\n",
    "imdb1['Votes']=Votes\n",
    "\n",
    "imdb1.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb1.to_csv('Question_9imdb1.csv')# saving data frame to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating connection to browser, opening url \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigating to desired page\n",
    "time.sleep(10)\n",
    "all_=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "try:\n",
    "    all_.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(all_.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lists to append scraped data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# scraping data from website\n",
    "dn=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in dn:\n",
    "    Dataset_name.append(i.text)\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table/tbody/tr/td[2]/p\")\n",
    "k=0\n",
    "for i in dt:\n",
    "    k=k+1\n",
    "    if k>=3:\n",
    "        if i.text!=' ':\n",
    "            Data_type.append(i.text)\n",
    "        else:\n",
    "            Data_type.append(\"not mentioned \")\n",
    "\n",
    "\n",
    "noi=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]/p\")\n",
    "k=0\n",
    "for i in noi:\n",
    "    k=k+1\n",
    "    if k>=2:\n",
    "        if i.text!=' ':\n",
    "            No_of_instances.append(i.text)\n",
    "        else:\n",
    "            No_of_instances.append(\"not mentioned \")\n",
    "            \n",
    "\n",
    "tsk=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]/p\")\n",
    "k=0\n",
    "for i in tsk:\n",
    "    k=k+1\n",
    "    if k>=2:\n",
    "        if i.text!=' ':\n",
    "            Task.append(i.text)\n",
    "        else:\n",
    "            Task.append(\"not mentioned \")\n",
    "            \n",
    "            \n",
    "            \n",
    "att=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p\")\n",
    "k=0\n",
    "for i in att:\n",
    "    k=k+1\n",
    "    if k>=2:\n",
    "        if i.text!=' ':\n",
    "            Attribute_type.append(i.text)\n",
    "        else:\n",
    "            Attribute_type.append(\"not mentioned \")\n",
    "            \n",
    "            \n",
    "noa=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p\")\n",
    "k=0\n",
    "for i in noa:\n",
    "    k=k+1\n",
    "    if k>=2:\n",
    "        if i.text!=' ':\n",
    "            No_of_attribute.append(i.text)\n",
    "        else:\n",
    "            No_of_attribute.append(\"not mentioned \")\n",
    "            \n",
    "ye=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p\")\n",
    "k=0\n",
    "for i in ye:\n",
    "    k=k+1\n",
    "    if k>=2:\n",
    "        if i.text!=' ':\n",
    "            Year.append(i.text)\n",
    "        else:\n",
    "            Year.append(\"not mentioned \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>not mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>not mentioned</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Dataset_name       Data_type                  Task  \\\n",
       "0                       Abalone   Multivariate        Classification    \n",
       "1                         Adult   Multivariate        Classification    \n",
       "2                     Annealing   Multivariate        Classification    \n",
       "3  Anonymous Microsoft Web Data  not mentioned   Recommender-Systems    \n",
       "4                    Arrhythmia   Multivariate        Classification    \n",
       "\n",
       "                Attribute_type No_of_instances No_of_attribute            Year  \n",
       "0  Categorical, Integer, Real            4177               8            1995   \n",
       "1        Categorical, Integer           48842              14            1996   \n",
       "2  Categorical, Integer, Real             798              38   not mentioned   \n",
       "3                 Categorical           37711             294            1998   \n",
       "4  Categorical, Integer, Real             452             279            1998   "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from scraped data\n",
    "UCI=pd.DataFrame({})\n",
    "\n",
    "UCI['Dataset_name']=Dataset_name\n",
    "UCI['Data_type']=Data_type\n",
    "UCI['Task']=Task\n",
    "UCI['Attribute_type']=Attribute_type\n",
    "UCI['No_of_instances']=No_of_instances\n",
    "UCI['No_of_attribute']=No_of_attribute\n",
    "UCI['Year']=Year\n",
    "\n",
    "UCI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI.to_csv('Question_10UCI.csv')# saving data frame to csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
